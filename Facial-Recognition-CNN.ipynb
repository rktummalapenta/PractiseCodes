{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcSVD9S3Va0TWWyU1nITfR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rktummalapenta/PractiseCodes/blob/master/Facial-Recognition-CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-GXZcdIPOu9",
        "outputId": "247e0942-c289-41e3-b8d5-d094ee19955a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas-datareader) (4.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post5-py3-none-any.whl size=2950 sha256=bbcf4a22316f71d0a96a81ae530780b1f1ce4f0af6bbad468dca840b51d670e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/1f/8d/4f812c590e074c1e928f5cec67bf5053b71f38e2648739403a\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post5\n"
          ]
        }
      ],
      "source": [
        "%pip install \\\n",
        "      sklearn \\\n",
        "      pandas \\\n",
        "      pandas-datareader \\\n",
        "      matplotlib \\\n",
        "      pillow \\\n",
        "      requests \\\n",
        "      h5py \\\n",
        "      tensorflow \\\n",
        "      keras \\\n",
        "      opencv-python \\\n",
        "      opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgvQWakJRpsE",
        "outputId": "22657fc2-5db4-429c-d46e-fcf9173e9984"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORL_faces.npz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import np_utils\n",
        "import itertools"
      ],
      "metadata": {
        "id": "LFdBQxn4PTxQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "data = np.load('ORL_faces.npz')\n",
        "\n",
        "# load the \"Train Images\"\n",
        "x_train = data['trainX']\n",
        "#normalize every image\n",
        "x_train = np.array(x_train,dtype='float32')/255\n",
        "\n",
        "x_test = data['testX']\n",
        "x_test = np.array(x_test,dtype='float32')/255\n",
        "\n",
        "# load the Label of Images\n",
        "y_train= data['trainY']\n",
        "y_test= data['testY']\n",
        "\n",
        "# show the train and test Data format\n",
        "print('x_train : {}'.format(x_train[:]))\n",
        "print('Y-train shape: {}'.format(y_train))\n",
        "print('x_test shape: {}'.format(x_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQn7LFGvPT0W",
        "outputId": "d0a288b6-53fe-4670-d49e-9d837b32d6e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train : [[0.1882353  0.19215687 0.1764706  ... 0.18431373 0.18039216 0.18039216]\n",
            " [0.23529412 0.23529412 0.24313726 ... 0.1254902  0.13333334 0.13333334]\n",
            " [0.15294118 0.17254902 0.20784314 ... 0.11372549 0.10196079 0.11372549]\n",
            " ...\n",
            " [0.44705883 0.45882353 0.44705883 ... 0.38431373 0.3764706  0.38431373]\n",
            " [0.4117647  0.4117647  0.41960785 ... 0.21176471 0.18431373 0.16078432]\n",
            " [0.45490196 0.44705883 0.45882353 ... 0.37254903 0.39215687 0.39607844]]\n",
            "Y-train shape: [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  2  2  2  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3\n",
            "  4  4  4  4  4  4  4  4  4  4  4  4  5  5  5  5  5  5  5  5  5  5  5  5\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7\n",
            "  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9\n",
            " 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11\n",
            " 12 12 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 15 15\n",
            " 16 16 16 16 16 16 16 16 16 16 16 16 17 17 17 17 17 17 17 17 17 17 17 17\n",
            " 18 18 18 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 19 19 19 19 19 19]\n",
            "x_test shape: (160, 10304)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "kaI-E9QIQk1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid= train_test_split(x_train, y_train, test_size=.05, random_state=42,)"
      ],
      "metadata": {
        "id": "gHBf3LPnRaGA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_rows=112\n",
        "im_cols=92\n",
        "batch_size=512\n",
        "im_shape=(im_rows, im_cols, 1)\n",
        "\n",
        "#change the size of images\n",
        "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], *im_shape)\n",
        "\n",
        "print('x_train shape: {}'.format(y_train.shape[0]))\n",
        "print('x_test shape: {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBjRKtdZPT5V",
        "outputId": "92bcbee6-0e80-4610-a1e8-f2e16e38af65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: 228\n",
            "x_test shape: (160,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filters= the depth of output image or kernels\n",
        "\n",
        "cnn_model= Sequential([\n",
        "    Conv2D(filters=36, kernel_size=7, activation='relu', input_shape= im_shape),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=54, kernel_size=5, activation='relu', input_shape= im_shape),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(2024, activation='relu'),\n",
        "     Dropout(0.5),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    #20 is the number of outputs\n",
        "    Dense(20, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',#'categorical_crossentropy',\n",
        "    optimizer=Adam(lr=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80ustpjjPT8V",
        "outputId": "b2bc606b-8452-4326-acd9-0e8972b3bd5d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTZniHmEPUAN",
        "outputId": "4e81a9ff-3db0-4d25-f7d6-b03cfa2f88f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 106, 86, 36)       1800      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 53, 43, 36)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 49, 39, 54)        48654     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 24, 19, 54)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 24624)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2024)              49841000  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              2073600   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                10260     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,500,114\n",
            "Trainable params: 52,500,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=cnn_model.fit(\n",
        "    np.array(x_train), np.array(y_train), batch_size=512,\n",
        "    epochs=250, verbose=2,\n",
        "    validation_data=(np.array(x_valid),np.array(y_valid)),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzYFmyngR_Vh",
        "outputId": "6c282f92-7615-4e85-fcf8-3bfbe8df3337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "1/1 - 11s - loss: 3.0018 - accuracy: 0.0482 - val_loss: 2.9897 - val_accuracy: 0.0833 - 11s/epoch - 11s/step\n",
            "Epoch 2/250\n",
            "1/1 - 13s - loss: 3.0017 - accuracy: 0.0395 - val_loss: 2.9886 - val_accuracy: 0.0833 - 13s/epoch - 13s/step\n",
            "Epoch 3/250\n",
            "1/1 - 13s - loss: 3.0018 - accuracy: 0.0746 - val_loss: 2.9909 - val_accuracy: 0.0833 - 13s/epoch - 13s/step\n",
            "Epoch 4/250\n",
            "1/1 - 15s - loss: 2.9886 - accuracy: 0.0614 - val_loss: 2.9953 - val_accuracy: 0.0833 - 15s/epoch - 15s/step\n",
            "Epoch 5/250\n",
            "1/1 - 9s - loss: 3.0019 - accuracy: 0.0658 - val_loss: 2.9958 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 6/250\n",
            "1/1 - 9s - loss: 2.9900 - accuracy: 0.0351 - val_loss: 2.9946 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 7/250\n",
            "1/1 - 12s - loss: 2.9815 - accuracy: 0.0746 - val_loss: 2.9928 - val_accuracy: 0.0000e+00 - 12s/epoch - 12s/step\n",
            "Epoch 8/250\n",
            "1/1 - 11s - loss: 2.9820 - accuracy: 0.0702 - val_loss: 2.9911 - val_accuracy: 0.0000e+00 - 11s/epoch - 11s/step\n",
            "Epoch 9/250\n",
            "1/1 - 11s - loss: 2.9813 - accuracy: 0.0570 - val_loss: 2.9896 - val_accuracy: 0.0000e+00 - 11s/epoch - 11s/step\n",
            "Epoch 10/250\n",
            "1/1 - 9s - loss: 2.9776 - accuracy: 0.0746 - val_loss: 2.9880 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 11/250\n",
            "1/1 - 9s - loss: 2.9610 - accuracy: 0.1009 - val_loss: 2.9865 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 12/250\n",
            "1/1 - 9s - loss: 2.9572 - accuracy: 0.1096 - val_loss: 2.9845 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 13/250\n",
            "1/1 - 10s - loss: 2.9387 - accuracy: 0.1316 - val_loss: 2.9837 - val_accuracy: 0.0833 - 10s/epoch - 10s/step\n",
            "Epoch 14/250\n",
            "1/1 - 9s - loss: 2.9515 - accuracy: 0.0746 - val_loss: 2.9815 - val_accuracy: 0.1667 - 9s/epoch - 9s/step\n",
            "Epoch 15/250\n",
            "1/1 - 9s - loss: 2.9460 - accuracy: 0.0921 - val_loss: 2.9814 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 16/250\n",
            "1/1 - 9s - loss: 2.9361 - accuracy: 0.1053 - val_loss: 2.9807 - val_accuracy: 0.0000e+00 - 9s/epoch - 9s/step\n",
            "Epoch 17/250\n",
            "1/1 - 8s - loss: 2.9204 - accuracy: 0.1360 - val_loss: 2.9792 - val_accuracy: 0.0000e+00 - 8s/epoch - 8s/step\n",
            "Epoch 18/250\n",
            "1/1 - 9s - loss: 2.9039 - accuracy: 0.1667 - val_loss: 2.9762 - val_accuracy: 0.0000e+00 - 9s/epoch - 9s/step\n",
            "Epoch 19/250\n",
            "1/1 - 9s - loss: 2.8888 - accuracy: 0.1404 - val_loss: 2.9702 - val_accuracy: 0.0000e+00 - 9s/epoch - 9s/step\n",
            "Epoch 20/250\n",
            "1/1 - 8s - loss: 2.8678 - accuracy: 0.1360 - val_loss: 2.9615 - val_accuracy: 0.0000e+00 - 8s/epoch - 8s/step\n",
            "Epoch 21/250\n",
            "1/1 - 10s - loss: 2.8535 - accuracy: 0.1886 - val_loss: 2.9517 - val_accuracy: 0.0833 - 10s/epoch - 10s/step\n",
            "Epoch 22/250\n",
            "1/1 - 8s - loss: 2.8517 - accuracy: 0.1623 - val_loss: 2.9407 - val_accuracy: 0.0833 - 8s/epoch - 8s/step\n",
            "Epoch 23/250\n",
            "1/1 - 9s - loss: 2.8289 - accuracy: 0.2105 - val_loss: 2.9299 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 24/250\n",
            "1/1 - 9s - loss: 2.8238 - accuracy: 0.1754 - val_loss: 2.9190 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 25/250\n",
            "1/1 - 8s - loss: 2.7722 - accuracy: 0.2105 - val_loss: 2.9082 - val_accuracy: 0.0833 - 8s/epoch - 8s/step\n",
            "Epoch 26/250\n",
            "1/1 - 9s - loss: 2.7486 - accuracy: 0.1842 - val_loss: 2.8904 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 27/250\n",
            "1/1 - 10s - loss: 2.7135 - accuracy: 0.2368 - val_loss: 2.8692 - val_accuracy: 0.1667 - 10s/epoch - 10s/step\n",
            "Epoch 28/250\n",
            "1/1 - 9s - loss: 2.7376 - accuracy: 0.2237 - val_loss: 2.8462 - val_accuracy: 0.0833 - 9s/epoch - 9s/step\n",
            "Epoch 29/250\n",
            "1/1 - 8s - loss: 2.6985 - accuracy: 0.2193 - val_loss: 2.8159 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 30/250\n",
            "1/1 - 9s - loss: 2.6819 - accuracy: 0.2281 - val_loss: 2.7792 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 31/250\n",
            "1/1 - 9s - loss: 2.6195 - accuracy: 0.2851 - val_loss: 2.7400 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 32/250\n",
            "1/1 - 8s - loss: 2.5518 - accuracy: 0.2719 - val_loss: 2.6923 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 33/250\n",
            "1/1 - 9s - loss: 2.5457 - accuracy: 0.2851 - val_loss: 2.6465 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 34/250\n",
            "1/1 - 9s - loss: 2.5593 - accuracy: 0.2588 - val_loss: 2.5926 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 35/250\n",
            "1/1 - 8s - loss: 2.4585 - accuracy: 0.3421 - val_loss: 2.5384 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 36/250\n",
            "1/1 - 9s - loss: 2.3961 - accuracy: 0.3596 - val_loss: 2.4818 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 37/250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = cnn_model.evaluate( np.array(x_test),  np.array(y_test), verbose=0)\n",
        "\n",
        "print('test los {:.4f}'.format(score[0]))\n",
        "print('test acc {:.4f}'.format(score[1]))"
      ],
      "metadata": {
        "id": "ic30M9J0SB3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f7dmO33BSIAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted =np.array( cnn_model.predict(x_test))\n",
        "#print(predicted)\n",
        "#print(y_test)\n",
        "ynew = cnn_model.predict_classes(x_test)\n",
        "\n",
        "\n",
        "Acc=accuracy_score(y_test, ynew)\n",
        "print(\"accuracy : \")\n",
        "print(Acc)\n",
        "#/tn, fp, fn, tp = confusion_matrix(np.array(y_test), ynew).ravel()\n",
        "cnf_matrix=confusion_matrix(np.array(y_test), ynew)\n",
        "\n",
        "y_test1 = np_utils.to_categorical(y_test, 20)\n",
        "\n"
      ],
      "metadata": {
        "id": "GBVGRTarSKub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        #print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Vo5GDCfbSYQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Confusion matrix, without normalization')\n",
        "print(cnf_matrix)\n",
        "\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix[1:10,1:10], classes=[0,1,2,3,4,5,6,7,8,9],\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix[11:20,11:20], classes=[10,11,12,13,14,15,16,17,18,19],\n",
        "                      title='Confusion matrix, without normalization')\n",
        "\n",
        "print(\"Confusion matrix:\\n%s\" % confusion_matrix(np.array(y_test), ynew))\n",
        "print(classification_report(np.array(y_test), ynew))"
      ],
      "metadata": {
        "id": "VE4iMWxhSYUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gqm9lJc9SYXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_SDrCNHSYaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsvNFXnCSYcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}